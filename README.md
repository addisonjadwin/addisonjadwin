# Addison Jadwin

## Bio
Hello! I'm Addison, a coterm masters student and ML researcher at Stanford. Below are some projects demonstrating my experience.

## Projects
- **ðŸ“ˆ Improving minBERT Multitask Performance through In-Domain Pretraining and NRL Learning** - [Link](https://www.researchgate.net/publication/369901299_Improving_minBERT_Performance_on_Multiple_Tasks_through_In-domain_Pretraining_Negatives_Ranking_Loss_Learning_and_Hyperparameter_Optimization)
  - We implemented minBERT, a miniaturized version of BERT with less parameters, and demonstrated practices for improving multitask performance (sentiment analysis, paraphrase detection, and semantic textual similarity) across three different datasets. We improved minBERT embeddings by implementing a recently published loss funciton, Multiple Negatives Ranking Loss Learning, as well as with a masked-language-model task on the datasets, leading to improvements of up to 32% above baseline. 
- **ðŸ“‘ AI Knowledge Navigator** - [Link](https://drive.google.com/file/d/120SoBaiETh0RUfio6yt_QHUd-CKgPBZM/view)
  - This is an LLM-powered agent I worked on which allows a user to quickly access and store semantic information across multiple documents. Users can query GPT-4 for desired information, both high-level or low-level, in their documents rather than manually searching for it. We found 4x acceleration compared to human reading speed. My role involved prompt engineering with the LLM to synthesize information from the documents and  backend indexing/storage of this information.
- **ðŸ©» Predicting Right Ventricular Ejection Fraction Using a Convolutional Neural Learning Model** - [Link](http://dx.doi.org/10.13140/RG.2.2.22407.68007)
  - We built an R(2+1)D CNN which, using transfer learning and 10-fold cross-validation, could predict right ventricular ejection fraction (RVEF), a measure of heart health, from echocardiogram videos. The dataset was mainly labeled with *left* ventricular ejection fraction (LVEF), a more common metric, so it involved using transfer learning from the optimal weights for LVEF in order to achieve high performance on the small RVEF dataset.
- **ðŸ‘¾ Helping and Hindering: Recursive Reasoning in a Multi-Agent MDP** - [Link](https://www.researchgate.net/publication/369901489_Helping_and_Hindering_Recursive_Reasoning_in_a_Multi-Agent_MDP)
  - We modeled 3rd-order recursive reasoning (reasoning about how another agent reasons about you) in a helping/hindering grid world scenario. Using online MDP planning algorithms, we were able to simulate intelligently-behaving agents which outperformed baseline models.
- **ðŸ§  Emotion Classification on EEG BMI Data with an LSTM+Conv Architecture** - [Link](https://drive.google.com/file/d/1Xu2JApRhIVjK-7Tp3H4m9KAKj7qv11nb/view?usp=sharing)
  - We beat the SOTA on an EEG brainwave dataset on emotion classification using a novel architecture with a combination of convolutional and LSTM layers, achieving 99.2% accuracy on the test data.
- **ðŸ’¬ Predictive Capabilities of Neural Network Language Models on Brain Data** - [Link](https://drive.google.com/file/d/1r3z0lM2dEEdqnnj3czdZkAnxVQou9zzr/view?usp=sharing)
  - I review the ability of language models (LLMs as well as early models like simple RNNs or word vector models) in predicting neural language processing data.
- **ðŸ‘‚ Self-Supervised & Unsupervised Neural Network Models of Auditory Processing in the Brain** - [Link](https://drive.google.com/file/d/1IxNdWHx69o_WgO0u4hRTnySVnehMEsp9/view?usp=sharing)
  - I review the ability of self-supervised/unsupervised models of auditory language data such as HuBERT or wav2vec in predicting neural audio processing data. 



## Education
- **ðŸŽ“ MS in Computer Science (AI concentration)** - Stanford University (2024)
  - Project & Coursework experience in ML/NLP.
- **ðŸŽ“ BS in Symbolic Systems** - Stanford University (2023)
  - GPA: 3.99
 
## Contact
- ðŸ’¼ LinkedIn: https://www.linkedin.com/in/ajadwin/
- ðŸ“© Email: addisonjadwin@hotmail.com

<!--
## Work Experience
- **Machine Learning Intern** - NIO (Jun - Sep 2023)
  - I built large transformer/autoencoder models to predict anomalous behavior in a dataset of unlabeled software log files. To do this, I leveraged insights from recently published papers in additioning to developing my own architecture and data processing pipeline.
- **Research Assistant** - Causality in Cognition Lab (Dec 2020 - Present)
  - I've led a long-term research project at Stanford aimed at building computational models to predict human decision-making in experiments related to causal responsibility judgments. To do this, I've worked with Bayesian regression models and linear mixed-effects models in R.
- **Software Engineering Intern** - Managed Discovery ( 2020 - Present)
  - I've led a long-term research project at Stanford aimed at building computational models to predict human decision-making in experiments related to causal responsibility judgments. To do this, I've worked with Bayesian regression models and linear mixed-effects models in R.

## Skills
- Programming Languages: [List of programming languages you're proficient in]
- Tools & Technologies: [List of tools, frameworks, libraries, etc. you're experienced with]
- Other Skills: [Any other relevant skills]
-->




<!--
**addisonjadwin/addisonjadwin** is a âœ¨ _special_ âœ¨ repository because its `README.md` (this file) appears on your GitHub profile.

Here are some ideas to get you started:

- ðŸ”­ Iâ€™m currently working on ...
- ðŸŒ± Iâ€™m currently learning ...
- ðŸ‘¯ Iâ€™m looking to collaborate on ...
- ðŸ¤” Iâ€™m looking for help with ...
- ðŸ’¬ Ask me about ...
- ðŸ“« How to reach me: ...
- ðŸ˜„ Pronouns: ...
- âš¡ Fun fact: ...
-->
